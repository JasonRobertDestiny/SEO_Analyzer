from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field
from typing import Dict, List, Optional

import asyncio
import json
import os

load_dotenv()


# Pydantic models for structured output
class EntityAnalysis(BaseModel):
    entity_assessment: str = Field(
        description="Detailed analysis of entity optimization"
    )
    knowledge_panel_readiness: int = Field(description="Score from 0-100")
    key_improvements: List[str] = Field(description="Top 3 improvements needed")


class CredibilityAnalysis(BaseModel):
    credibility_assessment: str = Field(description="Overall credibility analysis")
    neeat_scores: Dict[str, int] = Field(
        description="Individual N-E-E-A-T-T component scores"
    )
    trust_signals: List[str] = Field(description="Identified trust signals")


class ConversationAnalysis(BaseModel):
    conversation_readiness: str = Field(description="Overall assessment")
    query_patterns: List[str] = Field(description="Identified query patterns")
    engagement_score: int = Field(description="Score from 0-100")
    gaps: List[str] = Field(description="Identified conversational gaps")


class PlatformPresence(BaseModel):
    platform_coverage: Dict[str, str] = Field(
        description="Coverage analysis per platform"
    )
    visibility_scores: Dict[str, int] = Field(description="Scores per platform type")
    optimization_opportunities: List[str] = Field(description="List of opportunities")


class SEORecommendations(BaseModel):
    strategic_recommendations: List[str] = Field(
        description="Major strategic recommendations"
    )
    quick_wins: List[str] = Field(description="Immediate action items")
    long_term_strategy: List[str] = Field(description="Long-term strategic goals")
    priority_matrix: Dict[str, str] = Field(
        description="Priority matrix by impact/effort"
    )


class LLMSEOEnhancer:
    def __init__(self):
        self.llm = ChatOpenAI(
            model="Qwen/Qwen2.5-VL-72B-Instruct",
            api_key=os.environ.get("SILICONFLOW_API_KEY"),
            base_url="https://api.siliconflow.cn/v1",
            temperature=0,
            max_retries=2,
            max_tokens=2048,  # è¿›ä¸€æ­¥å‡å°‘tokenæ•°é‡æå‡é€Ÿåº¦
        )
        # é…ç½®è¶…æ—¶å‚æ•°
        self.timeout_duration = 60  # å‡å°‘åˆ°60ç§’
        self.single_chain_timeout = 20  # å•ä¸ªé“¾20ç§’è¶…æ—¶
        
        # ç®€åŒ–ç¼“å­˜æœºåˆ¶
        self._cache = {}
        self._setup_chains()

    def _setup_chains(self):
        """Setup modern LangChain runnable sequences using pipe syntax"""
        # Entity Analysis Chain
        entity_parser = PydanticOutputParser(pydantic_object=EntityAnalysis)

        entity_prompt = PromptTemplate.from_template(
            """Analyze SEO entity optimization (be concise):
            Data: {seo_data}
            
            Return JSON only with:
            - entity_assessment (brief)
            - knowledge_panel_readiness (0-100)
            - key_improvements (top 3)
            
            {format_instructions}
            """
        )

        self.entity_chain = (
            {
                "seo_data": RunnablePassthrough(),
                "format_instructions": lambda _: entity_parser.get_format_instructions(),
            }
            | entity_prompt
            | self.llm
            | entity_parser
        )

        # Credibility Analysis Chain
        credibility_parser = PydanticOutputParser(pydantic_object=CredibilityAnalysis)

        credibility_prompt = PromptTemplate.from_template(
            """Evaluate credibility (be brief):
            Data: {seo_data}
            
            Return JSON only:
            - credibility_assessment (brief)
            - neeat_scores (6 scores 0-100)
            - trust_signals (top 3)
            
            {format_instructions}
            """
        )

        self.credibility_chain = (
            {
                "seo_data": RunnablePassthrough(),
                "format_instructions": lambda _: credibility_parser.get_format_instructions(),
            }
            | credibility_prompt
            | self.llm
            | credibility_parser
        )

        # Conversation Analysis Chain
        conversation_parser = PydanticOutputParser(pydantic_object=ConversationAnalysis)

        conversation_prompt = PromptTemplate.from_template(
            """Analyze conversational search readiness (concise):
            Data: {seo_data}
            
            Return JSON only:
            - conversation_readiness (brief)
            - query_patterns (top 3)
            - engagement_score (0-100)
            - gaps (top 3)
            
            {format_instructions}
            """
        )

        self.conversation_chain = (
            {
                "seo_data": RunnablePassthrough(),
                "format_instructions": lambda _: conversation_parser.get_format_instructions(),
            }
            | conversation_prompt
            | self.llm
            | conversation_parser
        )

        # Platform Presence Chain
        platform_parser = PydanticOutputParser(pydantic_object=PlatformPresence)

        platform_prompt = PromptTemplate.from_template(
            """Analyze platform presence (brief):
            Data: {seo_data}
            
            Return JSON only:
            - platform_coverage (brief assessment)
            - visibility_scores (4 scores 0-100)
            - optimization_opportunities (top 3)
            
            {format_instructions}
            """
        )

        self.platform_chain = (
            {
                "seo_data": RunnablePassthrough(),
                "format_instructions": lambda _: platform_parser.get_format_instructions(),
            }
            | platform_prompt
            | self.llm
            | platform_parser
        )

        # Recommendations Chain
        recommendations_parser = PydanticOutputParser(
            pydantic_object=SEORecommendations
        )

        recommendations_prompt = PromptTemplate.from_template(
            """Generate strategic recommendations (concise):
            Analysis: {analysis_results}
            
            Return JSON only:
            - strategic_recommendations (top 3)
            - quick_wins (top 3)
            - long_term_strategy (top 3)
            - priority_matrix (4 brief items)
            
            {format_instructions}
            """
        )

        self.recommendations_chain = (
            {
                "analysis_results": RunnablePassthrough(),
                "format_instructions": lambda _: recommendations_parser.get_format_instructions(),
            }
            | recommendations_prompt
            | self.llm
            | recommendations_parser
        )

    async def enhance_seo_analysis(self, seo_data: Dict) -> Dict:
        """
        Enhanced SEO analysis using modern LangChain patterns with performance optimization
        """
        # åˆ›å»ºæ•°æ®ç¼“å­˜é”®
        import hashlib
        cache_key = hashlib.md5(json.dumps(seo_data, sort_keys=True).encode()).hexdigest()
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self._cache:
            print("ä½¿ç”¨ç¼“å­˜çš„åˆ†æç»“æœ")
            return self._cache[cache_key]
        
        # Convert seo_data to string for prompt insertion
        seo_data_str = json.dumps(seo_data, indent=2)
        
        try:
            # ä½¿ç”¨æ›´çŸ­çš„è¶…æ—¶æ§åˆ¶
            timeout_duration = self.timeout_duration  # 60ç§’æ€»è¶…æ—¶
            
            print(f"ğŸ¤– å¼€å§‹AIåˆ†æ (è¶…æ—¶: {timeout_duration}ç§’)")
            
            # ç®€åŒ–æ•°æ®ä»¥å‡å°‘tokenä½¿ç”¨
            simplified_data = self._simplify_seo_data(seo_data_str)
            
            # Run analysis chains in parallel with aggressive timeout
            tasks = [
                asyncio.wait_for(self.entity_chain.ainvoke(simplified_data), timeout=self.single_chain_timeout),
                asyncio.wait_for(self.credibility_chain.ainvoke(simplified_data), timeout=self.single_chain_timeout),
                asyncio.wait_for(self.conversation_chain.ainvoke(simplified_data), timeout=self.single_chain_timeout),
                asyncio.wait_for(self.platform_chain.ainvoke(simplified_data), timeout=self.single_chain_timeout),
            ]
            
            # ä½¿ç”¨gather with return_exceptions
            results = await asyncio.gather(*tasks, return_exceptions=True)
            entity_results, credibility_results, conversation_results, platform_results = results
            
            # å¤„ç†ç»“æœ
            processed_results = {}
            
            if not isinstance(entity_results, Exception):
                processed_results["entity_analysis"] = entity_results.model_dump()
                print("âœ… å®ä½“åˆ†æå®Œæˆ")
            else:
                print(f"âš ï¸ å®ä½“åˆ†æå¤±è´¥: {type(entity_results).__name__}")
                processed_results["entity_analysis"] = self._get_fallback_entity_analysis()
            
            if not isinstance(credibility_results, Exception):
                processed_results["credibility_analysis"] = credibility_results.model_dump()
                print("âœ… å¯ä¿¡åº¦åˆ†æå®Œæˆ")
            else:
                print(f"âš ï¸ å¯ä¿¡åº¦åˆ†æå¤±è´¥: {type(credibility_results).__name__}")
                processed_results["credibility_analysis"] = self._get_fallback_credibility_analysis()
            
            if not isinstance(conversation_results, Exception):
                processed_results["conversation_analysis"] = conversation_results.model_dump()
                print("âœ… å¯¹è¯åˆ†æå®Œæˆ")
            else:
                print(f"âš ï¸ å¯¹è¯åˆ†æå¤±è´¥: {type(conversation_results).__name__}")
                processed_results["conversation_analysis"] = self._get_fallback_conversation_analysis()
            
            if not isinstance(platform_results, Exception):
                processed_results["cross_platform_presence"] = platform_results.model_dump()
                print("âœ… å¹³å°åˆ†æå®Œæˆ")
            else:
                print(f"âš ï¸ å¹³å°åˆ†æå¤±è´¥: {type(platform_results).__name__}")
                processed_results["cross_platform_presence"] = self._get_fallback_platform_analysis()

            # Generate final recommendations with shorter timeout
            try:
                print("ğŸ“ ç”Ÿæˆæœ€ç»ˆå»ºè®®...")
                recommendations = await asyncio.wait_for(
                    self.recommendations_chain.ainvoke(
                        json.dumps(processed_results, indent=1)  # å‡å°‘ç¼©è¿›
                    ),
                    timeout=30  # å¢åŠ åˆ°30ç§’
                )
                processed_results["recommendations"] = recommendations.model_dump()
                print("âœ… å»ºè®®ç”Ÿæˆå®Œæˆ")
            except Exception as e:
                print(f"âš ï¸ å»ºè®®ç”Ÿæˆå¤±è´¥: {type(e).__name__}")
                processed_results["recommendations"] = self._get_fallback_recommendations()

            # Combine all results
            final_results = {
                **seo_data,
                **processed_results,
            }

            # ç¼“å­˜ç»“æœ
            formatted_output = self._format_output(final_results)
            self._cache[cache_key] = formatted_output
            
            # é™åˆ¶ç¼“å­˜å¤§å°
            if len(self._cache) > 20:  # å‡å°‘ç¼“å­˜å¤§å°
                # ç§»é™¤æœ€æ—§çš„ç¼“å­˜é¡¹
                oldest_key = next(iter(self._cache))
                del self._cache[oldest_key]
            
            print("ğŸ‰ AIåˆ†æå®Œæˆ!")
            return formatted_output
            
        except asyncio.TimeoutError:
            print("â° AIåˆ†æè¶…æ—¶ï¼Œè¿”å›åŸºç¡€åˆ†æç»“æœ")
            return self._get_fallback_full_analysis(seo_data)
        except Exception as e:
            print(f"âŒ AIåˆ†æå¤±è´¥: {e}")
            return self._get_fallback_full_analysis(seo_data)

    def _format_output(self, raw_analysis: Dict) -> Dict:
        """Format analysis results into a clean, structured output"""
        try:
            entity_score = raw_analysis.get("entity_analysis", {}).get("knowledge_panel_readiness", 50)
            
            neeat_scores = raw_analysis.get("credibility_analysis", {}).get("neeat_scores", {})
            credibility_score = sum(neeat_scores.values()) / max(len(neeat_scores), 1) if neeat_scores else 50
            
            conversation_score = raw_analysis.get("conversation_analysis", {}).get("engagement_score", 50)
            
            visibility_scores = raw_analysis.get("cross_platform_presence", {}).get("visibility_scores", {})
            platform_score = sum(visibility_scores.values()) / max(len(visibility_scores), 1) if visibility_scores else 50
            
            return {
                "summary": {
                    "entity_score": entity_score,
                    "credibility_score": credibility_score,
                    "conversation_score": conversation_score,
                    "platform_score": platform_score,
                },
                "detailed_analysis": raw_analysis,
                "quick_wins": raw_analysis.get("recommendations", {}).get("quick_wins", ["ä¼˜åŒ–é¡µé¢æ ‡é¢˜", "æ”¹å–„å…ƒæè¿°", "å¢åŠ å†…éƒ¨é“¾æ¥"]),
                "strategic_recommendations": raw_analysis.get("recommendations", {}).get("strategic_recommendations", ["æå‡å†…å®¹è´¨é‡", "å¢å¼ºæŠ€æœ¯SEO", "å»ºç«‹æƒå¨æ€§"]),
            }
        except Exception as e:
            print(f"æ ¼å¼åŒ–è¾“å‡ºå¤±è´¥: {e}")
            return self._get_fallback_full_analysis(raw_analysis)
    
    def _simplify_seo_data(self, seo_data_str: str) -> str:
        """ç®€åŒ–SEOæ•°æ®ä»¥å‡å°‘tokenä½¿ç”¨"""
        try:
            data = json.loads(seo_data_str)
            
            # åªä¿ç•™å…³é”®ä¿¡æ¯
            simplified = {
                "pages_count": len(data.get("pages", [])),
                "sample_pages": data.get("pages", [])[:2],  # åªå–å‰2é¡µä½œä¸ºæ ·æœ¬
                "top_keywords": data.get("keywords", {}).get("words", [])[:5],  # åªå–å‰5ä¸ªå…³é”®è¯
                "errors_count": len(data.get("errors", [])),
                "duplicate_pages": len(data.get("duplicate_pages", [])),
                "total_time": data.get("total_time", 0)
            }
            
            return json.dumps(simplified, indent=1, ensure_ascii=False)
        except:
            # å¦‚æœè§£æå¤±è´¥ï¼Œæˆªæ–­åŸå§‹æ•°æ®
            return seo_data_str[:1000] + "..." if len(seo_data_str) > 1000 else seo_data_str

    def _get_fallback_entity_analysis(self):
        """å®ä½“åˆ†æçš„å›é€€ç»“æœ"""
        return {
            "entity_assessment": "ğŸ¢ å®ä½“ä¼˜åŒ–åŸºç¡€åˆ†æï¼šç½‘ç«™éœ€è¦åŠ å¼ºå“ç‰Œå®ä½“ä¿¡å·ï¼Œæå‡åœ¨çŸ¥è¯†å›¾è°±ä¸­çš„è¡¨ç°ã€‚å»ºè®®å®Œå–„å…¬å¸ä¿¡æ¯é¡µé¢ï¼Œå¢åŠ ç»“æ„åŒ–æ•°æ®æ ‡è®°ï¼Œæå‡å“ç‰Œä¸€è‡´æ€§ã€‚",
            "knowledge_panel_readiness": 65,
            "key_improvements": [
                "ğŸ“‹ æ·»åŠ å®Œæ•´çš„Schema.orgç»“æ„åŒ–æ•°æ®æ ‡è®°",
                "ğŸ·ï¸ ä¼˜åŒ–å“ç‰Œåç§°åœ¨å„å¹³å°çš„ä¸€è‡´æ€§è¡¨ç°", 
                "ğŸ”— å¢å¼ºå®ä½“ç›¸å…³æ€§å’Œæƒå¨æ€§ä¿¡å·"
            ]
        }
    
    def _get_fallback_credibility_analysis(self):
        """å¯ä¿¡åº¦åˆ†æçš„å›é€€ç»“æœ"""
        return {
            "credibility_assessment": "ğŸ›¡ï¸ å¯ä¿¡åº¦è¯„ä¼°ï¼šç½‘ç«™å…·å¤‡åŸºæœ¬çš„ä¿¡ä»»ä¿¡å·ï¼Œä½†åœ¨ä¸“ä¸šæ€§å’Œé€æ˜åº¦æ–¹é¢è¿˜æœ‰æå‡ç©ºé—´ã€‚å»ºè®®å®Œå–„å…³äºæˆ‘ä»¬é¡µé¢ï¼Œæ·»åŠ ä¸“ä¸šèµ„è´¨è¯æ˜ï¼Œæå‡å†…å®¹çš„ä¸“ä¸šæ·±åº¦ã€‚",
            "neeat_scores": {
                "naturalness": 70,
                "entity": 65,
                "expertise": 60,
                "authority": 65,
                "trustworthiness": 68,
                "transparency": 62
            },
            "trust_signals": [
                "âœ… SSLè¯ä¹¦å’Œå®‰å…¨è¿æ¥å·²é…ç½®",
                "ğŸ“ è”ç³»ä¿¡æ¯æ¸…æ™°å¯è§",
                "â„¹ï¸ å…³äºé¡µé¢éœ€è¦è¿›ä¸€æ­¥å®Œå–„"
            ]
        }
    
    def _get_fallback_conversation_analysis(self):
        """å¯¹è¯åˆ†æçš„å›é€€ç»“æœ"""
        return {
            "conversation_readiness": "ğŸ—£ï¸ å¯¹è¯æœç´¢å‡†å¤‡åº¦ï¼šç½‘ç«™å†…å®¹ç»“æ„åŸºæœ¬åˆç†ï¼Œä½†éœ€è¦ä¼˜åŒ–ä»¥æ›´å¥½é€‚åº”è¯­éŸ³æœç´¢å’Œå¯¹è¯å¼æŸ¥è¯¢ã€‚å»ºè®®å¢åŠ FAQéƒ¨åˆ†ï¼Œä¼˜åŒ–é•¿å°¾å…³é”®è¯ï¼Œæå‡å†…å®¹çš„é—®ç­”æ ¼å¼ã€‚",
            "query_patterns": [
                "â“ ä¿¡æ¯æŸ¥è¯¢ç±»ï¼šç”¨æˆ·å¯»æ‰¾åŸºç¡€ä¿¡æ¯å’Œè§£ç­”",
                "âš–ï¸ æ¯”è¾ƒæŸ¥è¯¢ç±»ï¼šç”¨æˆ·æ¯”è¾ƒä¸åŒé€‰æ‹©å’Œæ–¹æ¡ˆ",
                "ğŸ“ æœ¬åœ°æŸ¥è¯¢ç±»ï¼šç”¨æˆ·å¯»æ‰¾é™„è¿‘çš„æœåŠ¡å’Œä¿¡æ¯"
            ],
            "engagement_score": 68,
            "gaps": [
                "â“ ç¼ºå°‘ç³»ç»Ÿæ€§çš„FAQé—®ç­”éƒ¨åˆ†",
                "ğŸ“Š å†…å®¹æ·±åº¦éœ€è¦æå‡ä»¥è¦†ç›–æ›´å¤šæŸ¥è¯¢æ„å›¾",
                "ğŸ¯ éœ€è¦ä¼˜åŒ–è‡ªç„¶è¯­è¨€å’Œé•¿å°¾å…³é”®è¯"
            ]
        }
    
    def _get_fallback_platform_analysis(self):
        """å¹³å°åˆ†æçš„å›é€€ç»“æœ"""
        return {
            "platform_coverage": {
                "search_engines": "ğŸ” æœç´¢å¼•æ“ï¼šåŸºç¡€SEOå·²å®æ–½ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–æŠ€æœ¯é…ç½®å’Œå†…å®¹è´¨é‡",
                "social_media": "ğŸ“± ç¤¾äº¤åª’ä½“ï¼šéœ€è¦å»ºç«‹æˆ–åŠ å¼ºç¤¾äº¤åª’ä½“å­˜åœ¨ï¼Œæå‡å“ç‰ŒçŸ¥ååº¦",
                "knowledge_graphs": "ğŸ§  çŸ¥è¯†å›¾è°±ï¼šéœ€è¦æ”¹å–„åœ¨GoogleçŸ¥è¯†é¢æ¿å’Œç›¸å…³å®ä½“ä¸­çš„è¡¨ç°"
            },
            "visibility_scores": {
                "google": 70,
                "bing": 65,
                "social": 45,
                "knowledge_graph": 58
            },
            "optimization_opportunities": [
                "ğŸª ä¼˜åŒ–Googleæˆ‘çš„å•†å®¶èµ„æ–™ï¼Œæå‡æœ¬åœ°æœç´¢è¡¨ç°",
                "ğŸ“± å¢å¼ºç¤¾äº¤åª’ä½“æ´»è·ƒåº¦ï¼Œå»ºç«‹å“ç‰Œç¤¾åŒº",
                "ğŸ”— æå‡åœ¨è¡Œä¸šçŸ¥è¯†å›¾è°±ä¸­çš„æƒå¨åœ°ä½",
                "ğŸ“Š ç›‘æ§å“ç‰Œæœç´¢ç»“æœé¡µé¢çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§"
            ]
        }
    
    def _get_fallback_recommendations(self):
        """æ¨èå»ºè®®çš„å›é€€ç»“æœ"""
        return {
            "strategic_recommendations": [
                "ğŸ¯ å»ºç«‹å®Œæ•´çš„å…³é”®è¯ç­–ç•¥ï¼šç ”ç©¶ç›®æ ‡å…³é”®è¯ï¼Œåˆ†ææœç´¢æ„å›¾ï¼Œåˆ¶å®šå†…å®¹è®¡åˆ’",
                "ğŸ—ï¸ ä¼˜åŒ–ç½‘ç«™æŠ€æœ¯æ¶æ„ï¼šæå‡é¡µé¢é€Ÿåº¦ï¼Œæ”¹å–„ç§»åŠ¨ç«¯ä½“éªŒï¼Œç¡®ä¿æœç´¢å¼•æ“å¯æŠ“å–æ€§",
                "ğŸ“ æå‡å†…å®¹è´¨é‡ï¼šåˆ›å»ºåŸåˆ›ã€æ·±åº¦ã€æœ‰ä»·å€¼çš„å†…å®¹ï¼Œæ»¡è¶³ç”¨æˆ·æœç´¢éœ€æ±‚",
                "ğŸ”— å»ºç«‹æƒå¨æ€§é“¾æ¥ï¼šè·å¾—é«˜è´¨é‡å¤–é“¾ï¼Œä¼˜åŒ–å†…éƒ¨é“¾æ¥ç»“æ„ï¼Œæå‡åŸŸåæƒé‡"
            ],
            "quick_wins": [
                "âœ… ä¼˜åŒ–é¡µé¢æ ‡é¢˜ï¼šç¡®ä¿æ¯é¡µæ ‡é¢˜ç‹¬ç‰¹ï¼ŒåŒ…å«ä¸»å…³é”®è¯ï¼Œæ§åˆ¶åœ¨30-60å­—ç¬¦",
                "ğŸ“„ å®Œå–„Metaæè¿°ï¼šç¼–å†™å¸å¼•äººçš„æè¿°ï¼ŒåŒ…å«å…³é”®è¯å’Œè¡ŒåŠ¨å·å¬ï¼Œ150-160å­—ç¬¦",
                "ğŸ·ï¸ æ·»åŠ Altæ ‡ç­¾ï¼šä¸ºæ‰€æœ‰å›¾ç‰‡æ·»åŠ æè¿°æ€§altæ ‡ç­¾ï¼Œæå‡å¯è®¿é—®æ€§å’ŒSEO",
                "ğŸ”§ ä¿®å¤æŠ€æœ¯é—®é¢˜ï¼šæ£€æŸ¥å¹¶ä¿®å¤404é”™è¯¯ã€é‡å¤å†…å®¹ã€ç¼ºå¤±æ ‡é¢˜ç­‰æŠ€æœ¯SEOé—®é¢˜",
                "ğŸ“± ä¼˜åŒ–ç§»åŠ¨ä½“éªŒï¼šç¡®ä¿ç½‘ç«™åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šæ­£å¸¸æ˜¾ç¤ºå’Œå¿«é€ŸåŠ è½½"
            ],
            "long_term_strategy": [
                "ğŸ“ˆ å»ºç«‹å†…å®¹è¥é”€ä½“ç³»ï¼šå®šæœŸå‘å¸ƒé«˜è´¨é‡å†…å®¹ï¼Œå»ºç«‹è¡Œä¸šæƒå¨åœ°ä½",
                "ğŸŒ æ‰©å±•æ•°å­—åŒ–å­˜åœ¨ï¼šä¼˜åŒ–ç¤¾äº¤åª’ä½“ï¼Œå»ºè®¾çŸ¥è¯†å›¾è°±ï¼Œæå‡å“ç‰ŒçŸ¥ååº¦", 
                "ğŸ“ åŸ¹å…»ä¸“ä¸šæƒå¨æ€§ï¼šå±•ç¤ºä¸“ä¸šçŸ¥è¯†ï¼Œè·å¾—è¡Œä¸šè®¤å¯ï¼Œå»ºç«‹ä¿¡ä»»åº¦",
                "ğŸ“Š æ•°æ®é©±åŠ¨ä¼˜åŒ–ï¼šæŒç»­ç›‘æ§SEOè¡¨ç°ï¼Œæ ¹æ®æ•°æ®è°ƒæ•´ç­–ç•¥ï¼Œä¿æŒç«äº‰ä¼˜åŠ¿"
            ],
            "priority_matrix": {
                "é«˜å½±å“-ä½æˆæœ¬": "ğŸš€ é¡µé¢æ ‡é¢˜å’ŒMetaæè¿°ä¼˜åŒ–ã€å†…éƒ¨é“¾æ¥ä¼˜åŒ–ã€æŠ€æœ¯SEOä¿®å¤",
                "é«˜å½±å“-é«˜æˆæœ¬": "ğŸ“ å†…å®¹æˆ˜ç•¥é‡å»ºã€ç½‘ç«™æ¶æ„æ”¹è¿›ã€ä¸“ä¸šSEOå›¢é˜Ÿå»ºè®¾",
                "ä½å½±å“-ä½æˆæœ¬": "ğŸ“± ç¤¾äº¤åª’ä½“ä¼˜åŒ–ã€å›¾ç‰‡altæ ‡ç­¾æ·»åŠ ã€å°å¹…å†…å®¹æ›´æ–°",
                "ä½å½±å“-é«˜æˆæœ¬": "ğŸ”„ å®Œæ•´ç½‘ç«™é‡å»ºã€å¤§è§„æ¨¡ä»˜è´¹æ¨å¹¿ã€å“ç‰Œé‡å¡‘"
            }
        }
    
    def _get_fallback_full_analysis(self, seo_data: Dict):
        """å®Œæ•´çš„å›é€€åˆ†æç»“æœ"""
        return {
            "summary": {
                "entity_score": 60,
                "credibility_score": 60,
                "conversation_score": 60,
                "platform_score": 60,
            },
            "detailed_analysis": {
                **seo_data,
                "entity_analysis": self._get_fallback_entity_analysis(),
                "credibility_analysis": self._get_fallback_credibility_analysis(),
                "conversation_analysis": self._get_fallback_conversation_analysis(),
                "cross_platform_presence": self._get_fallback_platform_analysis(),
                "recommendations": self._get_fallback_recommendations()
            },
            "quick_wins": self._get_fallback_recommendations()["quick_wins"],
            "strategic_recommendations": self._get_fallback_recommendations()["strategic_recommendations"],
        }


# Example usage with async support
async def enhanced_modern_analyze(
    site: str, sitemap: Optional[str] = None, api_key: str = None, **kwargs
):
    """
    Enhanced analysis incorporating modern SEO principles using LangChain
    """
    from pyseoanalyzer import analyze

    # Run original analysis
    original_results = analyze(site, sitemap, **kwargs)

    # Enhance with modern SEO analysis if API key provided
    if api_key:
        enhancer = LLMSEOEnhancer()
        enhanced_results = await enhancer.enhance_seo_analysis(original_results)
        return enhancer._format_output(enhanced_results)

    return original_results
